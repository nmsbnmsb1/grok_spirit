#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰¹å¤„ç†è„šæœ¬ï¼šå°†JSONå…ƒæ•°æ®å†™å…¥MP4è§†é¢‘æ–‡ä»¶
éåŽ†è¾“å…¥ç›®å½•ï¼Œä¸ºæ¯ä¸ªJSONæ–‡ä»¶æ‰¾åˆ°å¯¹åº”çš„MP4æ–‡ä»¶ï¼š
1) ç”¨ ffmpeg å†™å…¥ comment(structured_prompt) ä¸Ž title(original_prompt)
2) ç”¨ Windows COM å±žæ€§å†™å…¥ AuthorUrl(metadata.url) å¹¶å°† "Izumi.Qu" è¿½åŠ åˆ° Media.Writer
"""

import os
import subprocess
import argparse
import json
import pythoncom
import re
import shutil
import hashlib
from datetime import datetime
from collections import defaultdict
from win32com.propsys import propsys
from win32com.shell import shellcon

try:
    import toml

    TOML_AVAILABLE = True
except ImportError:
    TOML_AVAILABLE = False


# region è¾…åŠ©åŠŸèƒ½
def load_config():
    """
    åŠ è½½é…ç½®æ–‡ä»¶ï¼Œæ”¯æŒTOMLå’ŒJSONæ ¼å¼
    """
    # ä¼˜å…ˆå°è¯•TOMLæ ¼å¼
    toml_file = "config.toml"
    json_file = "config.json"

    if os.path.exists(toml_file):
        if not TOML_AVAILABLE:
            print("è­¦å‘Š: æ£€æµ‹åˆ°TOMLé…ç½®æ–‡ä»¶ä½†æœªå®‰è£…tomlåº“ï¼Œè¯·è¿è¡Œ: pip install toml")
            return {}
        try:
            with open(toml_file, "r", encoding="utf-8") as f:
                return toml.load(f)
        except Exception as e:
            print(f"è­¦å‘Š: è¯»å–TOMLé…ç½®æ–‡ä»¶å¤±è´¥: {e}")

    # å›žé€€åˆ°JSONæ ¼å¼
    if os.path.exists(json_file):
        try:
            with open(json_file, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            print(f"è­¦å‘Š: è¯»å–JSONé…ç½®æ–‡ä»¶å¤±è´¥: {e}")

    return {}


def find_ffmpeg(ffmpeg_path=None, common_paths=None):
    """
    æ™ºèƒ½æŸ¥æ‰¾FFmpegè·¯å¾„
    """
    # é¦–å…ˆæ£€æŸ¥æŒ‡å®šçš„è·¯å¾„
    if ffmpeg_path and os.path.exists(ffmpeg_path):
        return ffmpeg_path

    # æ£€æŸ¥PATHä¸­çš„ffmpeg
    if shutil.which("ffmpeg"):
        return "ffmpeg"

    # æ£€æŸ¥å¸¸è§è·¯å¾„
    if common_paths:
        for path in common_paths:
            if os.path.exists(path):
                return path
            if shutil.which(path):
                return path

    return None


def extract_uuid_from_url(url, max_length=0):
    """
    ä»ŽURLä¸­æå–poståŽçš„UUIDéƒ¨åˆ†
    ä¾‹å¦‚: https://grok.com/imagine/post/fa3f4731-15e3-4a53-ac93-2b2810a2c910
    è¿”å›ž: fa3f4731-15e3-4a53-ac93-2b2810a2c910
    """
    if not url:
        return ""

    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…post/åŽçš„UUID
    pattern = r"/post/([a-f0-9-]+)"
    match = re.search(pattern, url)
    if match:
        uuid = match.group(1)
        # å¦‚æžœè®¾ç½®äº†é•¿åº¦é™åˆ¶ï¼Œåˆ™æˆªå–
        if max_length > 0 and len(uuid) > max_length:
            uuid = uuid[:max_length]
        return uuid
    return ""


def apply_filename_prefix_replacement(filename, config):
    """
    æ ¹æ®é…ç½®æ›¿æ¢æ–‡ä»¶åå‰ç¼€
    å¦‚æžœé…ç½®å¯ç”¨ä¸”æ–‡ä»¶åä»¥ grok_video_ å¼€å¤´ï¼Œåˆ™æ›¿æ¢ä¸º grok-video-
    """
    replace_prefix = config.get("file_naming", {}).get(
        "replace_grok_video_prefix", True
    )

    if replace_prefix and filename.startswith("grok_video_"):
        return filename.replace("grok_video_", "grok-video-", 1)

    return filename


def load_video_prompt_templates(config_file="video_prompt_templates.json"):
    """åŠ è½½è§†é¢‘æç¤ºè¯æ¨¡æ¿é…ç½®æ–‡ä»¶"""
    if os.path.exists(config_file):
        try:
            with open(config_file, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            print(f"è­¦å‘Š: è¯»å–è§†é¢‘æç¤ºè¯æ¨¡æ¿é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            return {}
    return {}


def save_video_prompt_templates(config, config_file="video_prompt_templates.json"):
    """ä¿å­˜è§†é¢‘æç¤ºè¯æ¨¡æ¿é…ç½®æ–‡ä»¶"""
    try:
        # å¯¹æ¯ä¸ªåˆ†ç±»çš„æ¨¡æ¿æŒ‰keyæŽ’åº
        sorted_config = config.copy()
        for category_key, category in sorted_config["categories"].items():
            if "templates" in category:
                # æŒ‰keyæŽ’åºæ¨¡æ¿
                sorted_templates = dict(sorted(category["templates"].items()))
                category["templates"] = sorted_templates

        with open(config_file, "w", encoding="utf-8") as f:
            json.dump(sorted_config, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"ä¿å­˜è§†é¢‘æç¤ºè¯æ¨¡æ¿é…ç½®æ–‡ä»¶å¤±è´¥: {e}")


def migrate_existing_categories(templates_config):
    """
    è¿ç§»çŽ°æœ‰åˆ†ç±»æ•°æ®åˆ°æ–°çš„åˆ†ç±»ç»“æž„
    """

    # å®šä¹‰æ—§åˆ†ç±»åˆ°æ–°åˆ†ç±»çš„æ˜ å°„
    old_to_new_mapping = {
        "non_injection_non_dict": "regular_prompt",
        "non_injection_dict": "parameter_control",
        "injection_consistent": "strict_injection",
    }

    # æ£€æŸ¥æ˜¯å¦å·²ç»ä½¿ç”¨æ–°åˆ†ç±»ç»“æž„
    current_categories = templates_config.get("categories", {})
    has_new_structure = any(
        key in current_categories
        for key in ["regular_prompt", "parameter_control", "strict_injection"]
    )
    has_old_structure = any(
        key in current_categories
        for key in [
            "non_injection_non_dict",
            "non_injection_dict",
            "injection_consistent",
        ]
    )

    if has_new_structure and not has_old_structure:
        return

    print("å¼€å§‹è¿ç§»çŽ°æœ‰åˆ†ç±»æ•°æ®...")

    # æ–°çš„åˆ†ç±»ç»“æž„
    new_categories = {
        "regular_prompt": {
            "name": "å¸¸è§„æç¤ºè¯",
            "description": "éžinjectionå®Œå…¨ä¸€è‡´ï¼Œéžå­—å…¸ç±»åž‹ï¼Œé•¿åº¦åœ¨500ä»¥å†…",
            "priority": 1,
            "templates": {},
        },
        "parameter_control": {
            "name": "å‚æ•°æŽ§åˆ¶æç¤ºè¯",
            "description": "éžinjectionå®Œå…¨ä¸€è‡´ï¼Œå­—å…¸åž‹ï¼Œæˆ–è€…é•¿åº¦åœ¨500åŠä»¥ä¸Š",
            "priority": 2,
            "templates": {},
        },
        "strict_injection": {
            "name": "ä¸¥æ ¼æ³¨å…¥æç¤ºè¯",
            "description": "Injectionå®Œå…¨ä¸€è‡´",
            "priority": 3,
            "templates": {},
        },
    }

    # å¦‚æžœå·²ç»æœ‰æ–°ç»“æž„ï¼Œä¿ç•™çŽ°æœ‰æ•°æ®
    if has_new_structure:
        for key in ["regular_prompt", "parameter_control", "strict_injection"]:
            if key in current_categories and "templates" in current_categories[key]:
                new_categories[key]["templates"] = current_categories[key]["templates"]

    # è¿ç§»çŽ°æœ‰æ¨¡æ¿æ•°æ®
    migrated_count = 0
    for old_key, new_key in old_to_new_mapping.items():
        if old_key in templates_config["categories"]:
            old_category = templates_config["categories"][old_key]
            if "templates" in old_category:
                # å¯¹äºŽ non_injection_non_dictï¼Œéœ€è¦é‡æ–°åˆ†ç±»
                if old_key == "non_injection_non_dict":
                    for template_key, template_data in old_category[
                        "templates"
                    ].items():
                        prompt_content = template_data.get("prompt_content", "")
                        prompt_length = len(prompt_content)

                        # æ ¹æ®æ–°è§„åˆ™é‡æ–°åˆ†ç±»
                        if prompt_length >= 500:
                            new_categories["parameter_control"]["templates"][
                                template_key
                            ] = template_data
                        else:
                            new_categories["regular_prompt"]["templates"][
                                template_key
                            ] = template_data
                        migrated_count += 1
                else:
                    # ç›´æŽ¥è¿ç§»å…¶ä»–åˆ†ç±»
                    new_categories[new_key]["templates"] = old_category["templates"]
                    migrated_count += len(old_category["templates"])

    # æ›´æ–°åˆ†ç±»ç»“æž„
    templates_config["categories"] = new_categories

    print(f"è¿ç§»å®Œæˆï¼Œå…±è¿ç§» {migrated_count} ä¸ªæ¨¡æ¿")


# endregion

# region æç¤ºè¯æ¨¡å—


def categorize_prompt(meta_obj):
    """
    æ ¹æ®meta_objçš„original_promptå¯¹æç¤ºè¯è¿›è¡Œåˆ†ç±»

    è¿”å›ž: (category_key, prompt_content, prompt_key)
    """
    original_prompt = meta_obj.get("original_prompt", "")
    structured_prompt = meta_obj.get("structured_prompt", {})

    # å¤„ç†Noneå€¼ï¼Œç¡®ä¿ç©ºç™½æç¤ºè¯ä¸ºç©ºå­—ç¬¦ä¸²
    if original_prompt is None:
        original_prompt = ""

    # åˆ¤æ–­æ˜¯å¦ä¸ºInjectionå®Œå…¨ä¸€è‡´
    if original_prompt == "Injection completely consistent":
        category_key = "strict_injection"
        # å¯¹äºŽInjectionå®Œå…¨ä¸€è‡´çš„æƒ…å†µï¼Œä½¿ç”¨structured_promptä½œä¸ºå†…å®¹
        if isinstance(structured_prompt, dict):
            prompt_content = json.dumps(
                structured_prompt, ensure_ascii=False, separators=(",", ":")
            )
        else:
            prompt_content = str(structured_prompt)
    else:
        # éžInjectionå®Œå…¨ä¸€è‡´çš„æƒ…å†µï¼Œä½¿ç”¨original_promptä½œä¸ºå†…å®¹
        prompt_content = str(original_prompt)
        prompt_length = len(prompt_content)

        # åˆ¤æ–­original_promptæ˜¯å¦ä¸ºå­—å…¸æˆ–é•¿åº¦>=500
        if isinstance(original_prompt, dict) or prompt_length >= 500:
            category_key = "parameter_control"
        else:
            category_key = "regular_prompt"

    # ç”Ÿæˆæç¤ºè¯keyï¼šoriginal_promptå‰5-10ä¸ªå­—ç¬¦ + å“ˆå¸Œå€¼
    prompt_key = generate_prompt_key(original_prompt, prompt_content)

    return category_key, prompt_content, prompt_key


def generate_prompt_key(original_prompt, prompt_content):
    """
    ç”Ÿæˆæç¤ºè¯keyï¼šoriginal_promptå‰5-10ä¸ªåˆæ³•å­—ç¬¦ + å†…å®¹å“ˆå¸Œå€¼

    è¿”å›ž: ç»„åˆçš„keyå­—ç¬¦ä¸²
    """
    # å¤„ç†Noneå€¼
    if original_prompt is None:
        original_prompt = ""

    # å¦‚æžœæç¤ºè¯å†…å®¹ä¸ºç©ºï¼Œä½¿ç”¨ä¸“é—¨çš„keyåç§°
    if not prompt_content or prompt_content.strip() == "":
        return "grok_normal"

    # æå–original_promptçš„å‰5-10ä¸ªåˆæ³•å­—ç¬¦
    prompt_str = str(original_prompt)
    prefix_chars = []

    for char in prompt_str:
        if char.isalnum() or char in "_-":
            prefix_chars.append(char)
            if len(prefix_chars) >= 10:
                break

    # å–å‰5-10ä¸ªå­—ç¬¦ä½œä¸ºå‰ç¼€ï¼ˆç§»é™¤é•¿åº¦è‡ªè¡¥å®ŒåŠŸèƒ½ï¼‰
    prefix = "".join(prefix_chars[:10])

    # ç”Ÿæˆå†…å®¹å“ˆå¸Œå€¼
    content_hash = hashlib.md5(prompt_content.encode("utf-8")).hexdigest()[:8]

    # ç»„åˆå‰ç¼€å’Œå“ˆå¸Œå€¼
    return f"{prefix}_{content_hash}"


def update_video_prompt_templates(
    meta_files_info, config_file="video_prompt_templates.json"
):
    """
    æ›´æ–°è§†é¢‘æç¤ºè¯æ¨¡æ¿é…ç½®

    Args:
        meta_files_info: å…ƒæ•°æ®æ–‡ä»¶ä¿¡æ¯å­—å…¸
        config_file: é…ç½®æ–‡ä»¶è·¯å¾„
    """
    print("\n=== å¼€å§‹æ›´æ–°è§†é¢‘æç¤ºè¯æ¨¡æ¿é…ç½® ===")

    # åŠ è½½çŽ°æœ‰é…ç½®
    templates_config = load_video_prompt_templates(config_file)

    # åˆå§‹åŒ–é…ç½®ç»“æž„
    if "categories" not in templates_config:
        templates_config["categories"] = {
            "regular_prompt": {
                "name": "å¸¸è§„æç¤ºè¯",
                "description": "éžinjectionå®Œå…¨ä¸€è‡´ï¼Œéžå­—å…¸ç±»åž‹ï¼Œé•¿åº¦åœ¨500ä»¥å†…",
                "priority": 1,
                "templates": {},
            },
            "parameter_control": {
                "name": "å‚æ•°æŽ§åˆ¶æç¤ºè¯",
                "description": "éžinjectionå®Œå…¨ä¸€è‡´ï¼Œå­—å…¸åž‹ï¼Œæˆ–è€…é•¿åº¦åœ¨500åŠä»¥ä¸Š",
                "priority": 2,
                "templates": {},
            },
            "strict_injection": {
                "name": "ä¸¥æ ¼æ³¨å…¥æç¤ºè¯",
                "description": "Injectionå®Œå…¨ä¸€è‡´",
                "priority": 3,
                "templates": {},
            },
        }
    else:
        # è¿ç§»çŽ°æœ‰æ•°æ®åˆ°æ–°çš„åˆ†ç±»ç»“æž„
        migrate_existing_categories(templates_config)

    if "statistics" not in templates_config:
        templates_config["statistics"] = {
            "total_videos": 0,
            "total_urls": 0,
            "last_updated": "",
        }

    # ç»Ÿè®¡ä¿¡æ¯
    total_videos = 0
    total_urls = set()

    # å¤„ç†æ¯ä¸ªå…ƒæ•°æ®æ–‡ä»¶
    for base_name, meta_info in meta_files_info.items():
        meta_obj = meta_info["meta_obj"]

        # åˆ†ç±»æç¤ºè¯
        category_key, prompt_content, prompt_hash = categorize_prompt(meta_obj)

        # èŽ·å–URL
        url = meta_obj.get("metadata", {}).get("url", "")
        if url:
            total_urls.add(url)

        total_videos += 1

        # æ›´æ–°æ¨¡æ¿é…ç½®
        category = templates_config["categories"][category_key]

        if prompt_hash not in category["templates"]:
            # åˆ›å»ºæ–°æ¨¡æ¿
            category["templates"][prompt_hash] = {
                "prompt_content": prompt_content,
                "video_count": 0,
                "urls": set(),
                "first_seen": datetime.now().isoformat(),
                "last_seen": datetime.now().isoformat(),
            }

        # æ›´æ–°æ¨¡æ¿ç»Ÿè®¡
        template = category["templates"][prompt_hash]
        template["video_count"] += 1
        if url:
            # ç¡®ä¿urlsæ˜¯setç±»åž‹
            if isinstance(template["urls"], list):
                template["urls"] = set(template["urls"])
            template["urls"].add(url)
        template["last_seen"] = datetime.now().isoformat()

    # è½¬æ¢setä¸ºlistä»¥ä¾¿JSONåºåˆ—åŒ–
    for category in templates_config["categories"].values():
        for template in category["templates"].values():
            template["urls"] = list(template["urls"])

    # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
    templates_config["statistics"]["total_videos"] = total_videos
    templates_config["statistics"]["total_urls"] = len(total_urls)
    templates_config["statistics"]["last_updated"] = datetime.now().isoformat()

    # ä¿å­˜é…ç½®
    save_video_prompt_templates(templates_config, config_file)

    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    print(f"è§†é¢‘æç¤ºè¯æ¨¡æ¿é…ç½®æ›´æ–°å®Œæˆ:")
    print(f"  æ€»è§†é¢‘æ•°: {total_videos}")
    print(f"  æ€»URLæ•°: {len(total_urls)}")

    for category_key, category in templates_config["categories"].items():
        template_count = len(category["templates"])
        total_template_videos = sum(
            t["video_count"] for t in category["templates"].values()
        )
        print(
            f"  {category['name']}: {template_count} ä¸ªæ¨¡æ¿, {total_template_videos} ä¸ªè§†é¢‘"
        )

    print(f"é…ç½®æ–‡ä»¶å·²ä¿å­˜: {config_file}")


def parse_download_time(download_time_str):
    """
    è§£æždownload_timeå­—ç¬¦ä¸²ä¸ºdatetimeå¯¹è±¡
    æ ¼å¼: "2025/10/20 07:23:07"
    """
    try:
        return datetime.strptime(download_time_str, "%Y/%m/%d %H:%M:%S")
    except ValueError:
        # å¦‚æžœè§£æžå¤±è´¥ï¼Œè¿”å›žä¸€ä¸ªå¾ˆæ—©çš„æ—¶é—´
        return datetime.min


def get_input_prompt_for_grouping(meta_obj):
    """
    æ ¹æ®è§„åˆ™ç¡®å®šç”¨äºŽåˆ†ç»„çš„input_prompt
    å¦‚æžœoriginal_promptä¸æ˜¯"Injection completely consistent"ï¼Œå°±ç”¨original_prompt
    å¦åˆ™ç”¨structured_prompt
    """
    original_prompt = meta_obj.get("original_prompt", "")

    if original_prompt != "Injection completely consistent":
        return str(original_prompt)  # ç¡®ä¿è¿”å›žå­—ç¬¦ä¸²
    else:
        structured_prompt = meta_obj.get("structured_prompt", {})
        # å°†structured_promptè½¬æ¢ä¸ºå­—ç¬¦ä¸²ç”¨äºŽåˆ†ç»„
        try:
            if isinstance(structured_prompt, dict):
                return json.dumps(
                    structured_prompt, ensure_ascii=False, separators=(",", ":")
                )
            else:
                return str(structured_prompt)
        except Exception as e:
            print(f"è­¦å‘Š: å¤„ç†structured_promptæ—¶å‡ºé”™: {e}, å€¼: {structured_prompt}")
            return str(structured_prompt)


def calculate_file_naming_info(meta_files_info, config):
    """
    è®¡ç®—æ‰€æœ‰æ–‡ä»¶çš„å‘½åä¿¡æ¯
    è¿”å›ž: {filename: {'p': p_value, 'v': v_value, 'uuid': uuid}}
    """
    # èŽ·å–UUIDé•¿åº¦é™åˆ¶
    uuid_max_length = config.get("file_naming", {}).get("uuid_max_length", 0)

    # æŒ‰URLåˆ†ç»„ï¼ˆæ¯ä¸ªURLæ˜¯ä¸€ä¸ªç‹¬ç«‹çš„åˆ†ç»„ï¼‰
    url_groups = defaultdict(list)

    for filename, meta_info in meta_files_info.items():
        try:
            meta_obj = meta_info["meta_obj"]
            url = meta_obj.get("metadata", {}).get("url", "")
            uuid = extract_uuid_from_url(url, uuid_max_length)

            # ä½¿ç”¨UUIDä½œä¸ºåˆ†ç»„é”®ï¼Œå¦‚æžœæ²¡æœ‰UUIDåˆ™ä½¿ç”¨_blank_
            group_key = uuid if uuid else "_blank_"

            url_groups[group_key].append(
                {
                    "filename": filename,
                    "meta_info": meta_info,
                    "uuid": uuid,
                    "download_time": parse_download_time(
                        meta_obj.get("metadata", {}).get("download_time", "")
                    ),
                    "input_prompt": get_input_prompt_for_grouping(meta_obj),
                }
            )
        except Exception as e:
            print(f"é”™è¯¯: å¤„ç†æ–‡ä»¶ {filename} æ—¶å‡ºé”™: {e}")
            print(f"  meta_obj: {meta_info.get('meta_obj', {})}")
            continue

    naming_info = {}

    # å¯¹æ¯ä¸ªURLç»„ç‹¬ç«‹å¤„ç†
    for group_key, items in url_groups.items():
        # åœ¨URLç»„å†…æŒ‰input_promptåˆ†ç»„
        prompt_groups = defaultdict(list)

        for item in items:
            input_prompt = item["input_prompt"]
            prompt_groups[input_prompt].append(item)

        # æŒ‰åˆ†ç»„æ•°é‡å’Œæœ€å¤§download_timeæŽ’åºæ¥ç¡®å®šPå€¼ï¼ˆURLç»„å†…ç‹¬ç«‹ï¼‰
        sorted_prompt_groups = sorted(
            prompt_groups.items(),
            key=lambda x: (-len(x[1]), max(item["download_time"] for item in x[1])),
        )

        # åœ¨URLç»„å†…åˆ†é…På€¼ï¼ˆä»Ž1å¼€å§‹ï¼‰
        for p_value, (input_prompt, prompt_items) in enumerate(sorted_prompt_groups, 1):
            # åœ¨åŒä¸€ä¸ªPç»„å†…ï¼ŒæŒ‰download_timeä»Žå°åˆ°å¤§æŽ’åºæ¥ç¡®å®švå€¼
            sorted_items = sorted(prompt_items, key=lambda x: x["download_time"])

            for v_value, item in enumerate(sorted_items, 1):
                filename = item["filename"]
                uuid = item["uuid"]

                naming_info[filename] = {"p": p_value, "v": v_value, "uuid": uuid}

    return naming_info


# endregion

# region ä¸»å¤„ç†å‡½æ•°


def process_videos():
    """
    ä¸»å¤„ç†å‡½æ•°ï¼ŒéåŽ†è¾“å…¥ç›®å½•ï¼Œä¸ºè§†é¢‘åµŒå…¥å…ƒæ•°æ®ã€‚
    """
    print("--- å¼€å§‹å¤„ç†è§†é¢‘ ---")

    # åŠ è½½é…ç½®æ–‡ä»¶
    config = load_config()

    # é…ç½®å‚æ•°ï¼ˆå¯é€šè¿‡å‘½ä»¤è¡Œè¦†ç›–ï¼‰
    parser = argparse.ArgumentParser(description="æ‰¹å¤„ç†å°†JSONå…ƒæ•°æ®å†™å…¥MP4è§†é¢‘æ–‡ä»¶")
    # èŽ·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•
    script_dir = os.path.dirname(os.path.abspath(__file__))

    parser.add_argument(
        "ffmpeg_path",
        nargs="?",
        default=config.get("ffmpeg_path", r"E:\Program Files\ffmpeg.exe"),
        help="FFmpegç¨‹åºè·¯å¾„",
    )
    parser.add_argument(
        "input_dir",
        nargs="?",
        default=config.get("default_input_dir", script_dir),
        help="è¾“å…¥ç›®å½•è·¯å¾„",
    )
    parser.add_argument(
        "output_dir",
        nargs="?",
        default=config.get("default_output_dir", os.path.join(script_dir, "output")),
        help="è¾“å‡ºç›®å½•è·¯å¾„",
    )

    args = parser.parse_args()

    # æ™ºèƒ½æŸ¥æ‰¾FFmpegè·¯å¾„
    FFMPEG_PATH = find_ffmpeg(args.ffmpeg_path, config.get("common_ffmpeg_paths", []))
    if not FFMPEG_PATH:
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°FFmpegç¨‹åº")
        print(f"è¯·æ£€æŸ¥ä»¥ä¸‹è·¯å¾„:")
        print(f"  æŒ‡å®šè·¯å¾„: {args.ffmpeg_path}")
        print(f"  ç³»ç»ŸPATH: ffmpeg")
        if config.get("common_ffmpeg_paths"):
            print(f"  å¸¸è§è·¯å¾„: {', '.join(config.get('common_ffmpeg_paths', []))}")
        print(f"è¯·å®‰è£…FFmpegæˆ–å°†è·¯å¾„æ·»åŠ åˆ°é…ç½®æ–‡ä»¶config.jsonä¸­")
        return

    print(f"ä½¿ç”¨FFmpegè·¯å¾„: {FFMPEG_PATH}")

    INPUT_DIR = args.input_dir
    OUTPUT_DIR = args.output_dir
    META_EXTENSION = ".json"
    VIDEO_EXTENSION = ".mp4"

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    if not os.path.exists(OUTPUT_DIR):
        print(f"åˆ›å»ºè¾“å‡ºç›®å½•: {OUTPUT_DIR}")
        os.makedirs(OUTPUT_DIR)

    # æŸ¥æ‰¾æ‰€æœ‰å…ƒæ•°æ®æ–‡ä»¶å’Œè§†é¢‘æ–‡ä»¶
    meta_files = [f for f in os.listdir(INPUT_DIR) if f.endswith(META_EXTENSION)]
    video_files = [f for f in os.listdir(INPUT_DIR) if f.endswith(VIDEO_EXTENSION)]

    print(f"ç›®å½•ç»Ÿè®¡:")
    print(f"  - JSONæ–‡ä»¶: {len(meta_files)} ä¸ª")
    print(f"  - MP4æ–‡ä»¶: {len(video_files)} ä¸ª")
    print(f"\nå¼€å§‹å¤„ç†...")

    def find_matching_video(meta_obj, meta_base_name, video_files, input_dir):
        """
        æ™ºèƒ½åŒ¹é…è§†é¢‘æ–‡ä»¶ï¼ŒæŒ‰ä¼˜å…ˆçº§è¿›è¡Œ3è½®æŸ¥æ‰¾ï¼š
        1. ä½¿ç”¨JSONå†…éƒ¨çš„video_idåŒ¹é…
        2. åŒååŒ¹é…
        3. å°†grok_video_æ›¿æ¢æˆgrok-video-å†åŒ¹é…
        """
        video_extension = ".mp4"

        # ç¬¬ä¸€è½®ï¼šä½¿ç”¨video_idåŒ¹é…
        if "metadata" in meta_obj and "video_id" in meta_obj["metadata"]:
            video_id = meta_obj["metadata"]["video_id"]
            for video_filename in video_files:
                video_base_name = os.path.splitext(video_filename)[0]
                if video_base_name == video_id:
                    video_path = os.path.join(input_dir, video_filename)
                    if os.path.exists(video_path):
                        return video_path, f"video_idåŒ¹é…: {video_id}"

        # ç¬¬äºŒè½®ï¼šåŒååŒ¹é…
        expected_video_filename = meta_base_name + video_extension
        expected_video_path = os.path.join(input_dir, expected_video_filename)
        if os.path.exists(expected_video_path):
            return expected_video_path, f"åŒååŒ¹é…: {expected_video_filename}"

        # ç¬¬ä¸‰è½®ï¼šgrok_video_æ›¿æ¢åŒ¹é…
        if "grok_video_" in meta_base_name:
            modified_base_name = meta_base_name.replace("grok_video_", "grok-video-")
            modified_video_filename = modified_base_name + video_extension
            modified_video_path = os.path.join(input_dir, modified_video_filename)
            if os.path.exists(modified_video_path):
                return modified_video_path, f"æ›¿æ¢åŒ¹é…: {modified_video_filename}"

        return None, "æœªæ‰¾åˆ°åŒ¹é…çš„è§†é¢‘æ–‡ä»¶"

    # ç¬¬ä¸€æ­¥ï¼šè¯»å–æ‰€æœ‰å…ƒæ•°æ®æ–‡ä»¶å¹¶æ£€æŸ¥å¯¹åº”çš„è§†é¢‘æ–‡ä»¶
    meta_files_info = {}
    failed_reads = []
    missing_videos = []
    missing_json_videos = []

    # åˆ›å»ºæ‰€æœ‰MP4æ–‡ä»¶çš„åŸºç¡€åç§°é›†åˆ
    all_video_base_names = set()
    for video_filename in video_files:
        base_name = os.path.splitext(video_filename)[0]
        all_video_base_names.add(base_name)

    for meta_filename in meta_files:
        base_name = os.path.splitext(meta_filename)[0]
        source_meta_path = os.path.join(INPUT_DIR, meta_filename)

        try:
            with open(source_meta_path, "r", encoding="utf-8") as f:
                meta_obj = json.load(f)

                # ä½¿ç”¨æ™ºèƒ½åŒ¹é…å‡½æ•°æŸ¥æ‰¾å¯¹åº”çš„è§†é¢‘æ–‡ä»¶
                video_path, match_info = find_matching_video(
                    meta_obj, base_name, video_files, INPUT_DIR
                )

                if video_path is None:
                    missing_videos.append(f"{base_name}: {match_info}")
                    continue

                meta_files_info[base_name] = {
                    "meta_obj": meta_obj,
                    "meta_path": source_meta_path,
                    "video_path": video_path,
                    "match_info": match_info,
                }
        except Exception as e:
            failed_reads.append(f"{meta_filename}: {e}")
            continue

    if failed_reads:
        print(f"è­¦å‘Š: {len(failed_reads)} ä¸ªå…ƒæ•°æ®æ–‡ä»¶è¯»å–å¤±è´¥:")
        for failed in failed_reads:
            print(f"  - {failed}")

    if missing_videos:
        print(f"è­¦å‘Š: {len(missing_videos)} ä¸ªå…ƒæ•°æ®æ–‡ä»¶ç¼ºå°‘å¯¹åº”çš„è§†é¢‘æ–‡ä»¶:")
        for missing in missing_videos:
            print(f"  - {missing}")

    if missing_json_videos:
        print(f"è·³è¿‡: {len(missing_json_videos)} ä¸ªMP4æ–‡ä»¶ç¼ºå°‘å¯¹åº”çš„JSONæ–‡ä»¶:")
        for missing in missing_json_videos:
            print(f"  - {missing}.mp4")

    # è®¡ç®—çœŸæ­£ç¼ºå°‘JSONçš„MP4æ–‡ä»¶ï¼ˆæ²¡æœ‰è¢«ä»»ä½•JSONæ–‡ä»¶åŒ¹é…çš„MP4æ–‡ä»¶ï¼‰
    matched_video_base_names = set()
    for base_name, info in meta_files_info.items():
        # ä»Žè§†é¢‘è·¯å¾„ä¸­æå–åŸºç¡€åç§°
        video_path = info["video_path"]
        video_filename = os.path.basename(video_path)
        video_base_name = os.path.splitext(video_filename)[0]
        matched_video_base_names.add(video_base_name)

    # æ‰¾å‡ºçœŸæ­£ç¼ºå°‘JSONçš„MP4æ–‡ä»¶
    missing_json_base_names = all_video_base_names - matched_video_base_names
    for base_name in missing_json_base_names:
        missing_json_videos.append(base_name)

    # æ˜¾ç¤ºåŒ¹é…ç»Ÿè®¡ä¿¡æ¯
    if meta_files_info:
        print(f"\nåŒ¹é…ç»Ÿè®¡:")
        match_types = {}
        for base_name, info in meta_files_info.items():
            match_info = info.get("match_info", "æœªçŸ¥")
            match_type = match_info.split(":")[0] if ":" in match_info else match_info
            match_types[match_type] = match_types.get(match_type, 0) + 1

        for match_type, count in match_types.items():
            print(f"  - {match_type}: {count} ä¸ªæ–‡ä»¶")

    # è®¡ç®—å‘½åä¿¡æ¯
    naming_info = calculate_file_naming_info(meta_files_info, config)
    print(f"å‘½åä¿¡æ¯è®¡ç®—å®Œæˆï¼Œå…± {len(naming_info)} ä¸ªæ–‡ä»¶å¯å¤„ç†")

    # æ›´æ–°è§†é¢‘æç¤ºè¯æ¨¡æ¿é…ç½®
    update_video_prompt_templates(meta_files_info)

    success_count = 0
    fail_count = 0
    raw_copy_count = 0
    miss_json_count = 0

    # åªå¤„ç†æœ‰å‘½åä¿¡æ¯çš„æ–‡ä»¶ï¼ˆå³é¢„å¤„ç†é˜¶æ®µé€šè¿‡çš„æ–‡ä»¶ï¼‰
    for base_name in naming_info.keys():
        meta_filename = base_name + META_EXTENSION
        video_filename = base_name + VIDEO_EXTENSION

        source_meta_path = os.path.join(INPUT_DIR, meta_filename)
        source_video_path = os.path.join(INPUT_DIR, video_filename)

        # ç”Ÿæˆæ–°çš„æ–‡ä»¶å
        naming_data = naming_info[base_name]
        uuid = naming_data["uuid"]
        p_value = naming_data["p"]
        v_value = naming_data["v"]

        # ä»Žé…ç½®æ–‡ä»¶èŽ·å–å‘½åè®¾ç½®
        file_naming_config = config.get("file_naming", {})
        prefix = file_naming_config.get("prefix", "grok_video")
        separator = file_naming_config.get("separator", "_")

        # æž„å»ºæ–‡ä»¶åï¼Œå¤„ç†UUIDä¸ºç©ºçš„æƒ…å†µ
        if uuid:
            new_filename = f"{prefix}{separator}{uuid}{separator}P{p_value}{separator}v{v_value}{VIDEO_EXTENSION}"
        else:
            new_filename = (
                f"{prefix}{separator}P{p_value}{separator}v{v_value}{VIDEO_EXTENSION}"
            )

        # åº”ç”¨æ–‡ä»¶åå‰ç¼€æ›¿æ¢
        new_filename = apply_filename_prefix_replacement(new_filename, config)
        output_video_path = os.path.join(OUTPUT_DIR, new_filename)

        # 1. æ£€æŸ¥è¾“å‡ºæ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼Œå¦‚æžœå­˜åœ¨åˆ™åˆ é™¤
        if os.path.exists(output_video_path):
            try:
                os.remove(output_video_path)
            except Exception as e:
                print(f"âŒ {base_name}: æ— æ³•åˆ é™¤å·²å­˜åœ¨çš„æ–‡ä»¶ - {e}")
                fail_count += 1
                continue

        # 2. è§†é¢‘æ–‡ä»¶æ£€æŸ¥å·²åœ¨é¢„å¤„ç†é˜¶æ®µå®Œæˆï¼Œç›´æŽ¥ä½¿ç”¨é¢„å¤„ç†çš„ç»“æžœ
        source_video_path = meta_files_info[base_name]["video_path"]

        # 2. ä½¿ç”¨å·²è¯»å–çš„å…ƒæ•°æ®å†…å®¹
        meta_obj = meta_files_info[base_name]["meta_obj"]

        # commentï¼šåªå­˜ structured_prompt
        structured_prompt = meta_obj.get("structured_prompt", {})
        metadata_content = json.dumps(
            structured_prompt, ensure_ascii=False, separators=(",", ":")
        )
        # keywordsï¼šå­˜ metadata.url
        metadata_url = ""
        try:
            metadata_url = meta_obj.get("metadata", {}).get("url", "") or ""
        except Exception:
            metadata_url = ""
        # å‰¯æ ‡é¢˜ï¼šæ”¾ original_prompt
        original_prompt = meta_obj.get("original_prompt", "") or ""

        # 3. ä½¿ç”¨ ffmpeg å†™å…¥ commentã€title å’Œ genre
        try:
            command = [
                FFMPEG_PATH,
                "-i",
                source_video_path,
                "-c",
                "copy",
                "-map_metadata",
                "0",
                "-metadata",
                f"comment={metadata_content}",  # \u00a9cmt
                "-metadata",
                f"title={original_prompt}",  # \u00a9nam
                "-metadata",
                f"genre={metadata_url}",  # \u00a9gen
                "-y",
                output_video_path,
            ]

            # æ‰§è¡Œ ffmpeg å‘½ä»¤
            result = subprocess.run(
                command, check=True, capture_output=True, text=True, encoding="utf-8"
            )

            # 4. ä½¿ç”¨ Windows COM å±žæ€§å†™å…¥ Writer
            def write_extended_properties(dst_path, writer_to_add):
                try:
                    pythoncom.CoInitialize()
                    ps = propsys.SHGetPropertyStoreFromParsingName(
                        dst_path,
                        None,
                        shellcon.GPS_READWRITE,
                        propsys.IID_IPropertyStore,
                    )

                    # Writer (System.Media.Writer) - å†™å…¥å¤šä¸ªä½œè€…ï¼ˆç”¨åˆ†å·åˆ†éš”ï¼‰
                    try:
                        if writer_to_add:
                            pkey_writer = propsys.PSGetPropertyKeyFromName(
                                "System.Media.Writer"
                            )
                            if isinstance(writer_to_add, list):
                                # å°†å¤šä¸ªä½œè€…ç”¨åˆ†å·è¿žæŽ¥æˆä¸€ä¸ªå­—ç¬¦ä¸²
                                writer_string = "; ".join(writer_to_add)
                                ps.SetValue(
                                    pkey_writer, propsys.PROPVARIANTType(writer_string)
                                )
                            else:
                                # å•ä¸ªå­—ç¬¦ä¸²
                                ps.SetValue(
                                    pkey_writer, propsys.PROPVARIANTType(writer_to_add)
                                )
                    except Exception as e:
                        print(f"  -> è­¦å‘Š: å†™å…¥ Writer å¤±è´¥: {e}")

                    ps.Commit()
                finally:
                    try:
                        pythoncom.CoUninitialize()
                    except Exception:
                        pass

            # ä»Žé…ç½®æ–‡ä»¶èŽ·å–ä½œè€…åˆ—è¡¨
            writer_names = config.get("writer_names", ["Izumi.Qu", "Grok"])
            write_extended_properties(output_video_path, writer_names)

            print(f"âœ… {base_name} -> {new_filename}")
            success_count += 1

        except subprocess.CalledProcessError as e:
            # å¦‚æžœ FFmpeg æ‰§è¡Œå¤±è´¥
            print(f"âŒ {base_name}: FFmpeg æ‰§è¡Œå¤±è´¥ - {e.stderr[:100]}...")
            fail_count += 1
        except FileNotFoundError:
            print(f"âŒ {base_name}: æ‰¾ä¸åˆ° FFmpeg ç¨‹åº")
            fail_count += 1

    # å¤„ç†ç¼ºå°‘JSONçš„MP4æ–‡ä»¶ - å¤åˆ¶åˆ°è¾“å‡ºç›®å½•å¹¶æ·»åŠ raw_å‰ç¼€
    if missing_json_videos:
        print(f"\nå¼€å§‹å¤åˆ¶ç¼ºå°‘JSONçš„MP4æ–‡ä»¶...")

    for base_name in missing_json_videos:
        filename = f"{base_name}.mp4"
        source_video_path = os.path.join(INPUT_DIR, filename)

        # ç”Ÿæˆå¸¦_rawåŽç¼€çš„æ–°æ–‡ä»¶å
        base_name_without_ext = os.path.splitext(filename)[0]
        raw_filename = f"{base_name_without_ext}_raw.mp4"

        # åº”ç”¨æ–‡ä»¶åå‰ç¼€æ›¿æ¢
        raw_filename = apply_filename_prefix_replacement(raw_filename, config)
        output_video_path = os.path.join(OUTPUT_DIR, raw_filename)

        try:
            # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼Œå¦‚æžœå­˜åœ¨åˆ™åˆ é™¤
            if os.path.exists(output_video_path):
                os.remove(output_video_path)

            # å¤åˆ¶æ–‡ä»¶
            shutil.copy2(source_video_path, output_video_path)
            print(f"ðŸ“‹ {base_name} -> {raw_filename}")
            raw_copy_count += 1

        except Exception as e:
            print(f"âŒ {base_name}: å¤åˆ¶å¤±è´¥ - {e}")
            fail_count += 1

    # å¤„ç†ç¼ºå°‘è§†é¢‘æ–‡ä»¶çš„JSONæ–‡ä»¶ - å¤åˆ¶åˆ°è¾“å‡ºç›®å½•å¹¶æ·»åŠ _missåŽç¼€
    if missing_videos:
        print(f"\nå¼€å§‹å¤„ç†ç¼ºå°‘è§†é¢‘æ–‡ä»¶çš„JSONæ–‡ä»¶...")

    for missing_video_item in missing_videos:
        # è§£æžæ–‡ä»¶å (æ ¼å¼: "filename: æ‰¾ä¸åˆ°å¯¹åº”çš„è§†é¢‘æ–‡ä»¶")
        base_name = missing_video_item.split(":")[0]
        json_filename = f"{base_name}.json"
        source_json_path = os.path.join(INPUT_DIR, json_filename)

        try:
            # è¯»å–JSONæ–‡ä»¶å†…å®¹ä»¥æå–UUID
            with open(source_json_path, "r", encoding="utf-8") as f:
                meta_obj = json.load(f)

            # å°è¯•ä»Žmetadata.urlä¸­æå–UUID
            url = meta_obj.get("metadata", {}).get("url", "")
            uuid = extract_uuid_from_url(
                url, config.get("file_naming", {}).get("uuid_max_length", 0)
            )

            # ç”Ÿæˆå¸¦_missåŽç¼€çš„æ–°æ–‡ä»¶å
            if uuid:
                miss_filename = f"{base_name}_{uuid}_miss.json"
            else:
                miss_filename = f"{base_name}_miss.json"

            # åº”ç”¨æ–‡ä»¶åå‰ç¼€æ›¿æ¢
            miss_filename = apply_filename_prefix_replacement(miss_filename, config)
            output_json_path = os.path.join(OUTPUT_DIR, miss_filename)

            # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼Œå¦‚æžœå­˜åœ¨åˆ™åˆ é™¤
            if os.path.exists(output_json_path):
                os.remove(output_json_path)

            # å¤åˆ¶æ–‡ä»¶
            shutil.copy2(source_json_path, output_json_path)
            print(f"ðŸ“„ {base_name} -> {miss_filename}")
            miss_json_count += 1

        except Exception as e:
            print(f"âŒ {base_name}: å¤„ç†JSONå¤±è´¥ - {e}")
            fail_count += 1

    # è®¡ç®—è·³è¿‡çš„æ–‡ä»¶æ•°é‡ï¼ˆåªåŒ…æ‹¬è¯»å–å¤±è´¥çš„JSONæ–‡ä»¶ï¼‰
    skipped_count = len(failed_reads)

    print(f"\n{'='*50}")
    print(f"å¤„ç†å®Œæˆ:")
    print(f"  âœ… æˆåŠŸå¤„ç†: {success_count} ä¸ª (å¸¦å…ƒæ•°æ®çš„è§†é¢‘)")
    print(f"  ðŸ“‹ å¤åˆ¶åŽŸå§‹: {raw_copy_count} ä¸ª (_rawåŽç¼€çš„è§†é¢‘)")
    print(f"  ðŸ“„ å¤„ç†JSON: {miss_json_count} ä¸ª (_missåŽç¼€çš„JSON)")
    print(f"  âŒ å¤±è´¥: {fail_count} ä¸ª")
    print(f"  â­ï¸ è·³è¿‡: {skipped_count} ä¸ª")
    if skipped_count:
        print(f"\nè·³è¿‡è¯¦æƒ…:")
        print(f"  - JSONè¯»å–å¤±è´¥: {len(failed_reads)} ä¸ª")
    print(f"\næ–‡ä»¶ç»Ÿè®¡:")
    print(f"  - è¾“å…¥MP4æ–‡ä»¶: {len(video_files)} ä¸ª")
    print(f"  - è¾“å…¥JSONæ–‡ä»¶: {len(meta_files)} ä¸ª")
    print(f"  - è¾“å‡ºæ–‡ä»¶æ€»æ•°: {success_count + raw_copy_count + miss_json_count} ä¸ª")
    print(f"    * è§†é¢‘æ–‡ä»¶: {success_count + raw_copy_count} ä¸ª")
    print(f"    * JSONæ–‡ä»¶: {miss_json_count} ä¸ª")
    if success_count > 0 or raw_copy_count > 0 or miss_json_count > 0:
        print(f"è¾“å‡ºç›®å½•: {OUTPUT_DIR}")


if __name__ == "__main__":
    process_videos()

# endregion
